{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((2, 1), ()), types: (tf.int32, tf.float32)>\n",
      "[(<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "array([[1],\n",
      "       [2]])>, <tf.Tensor: shape=(), dtype=float32, numpy=0.1>), (<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "array([[3],\n",
      "       [4]])>, <tf.Tensor: shape=(), dtype=float32, numpy=0.2>), (<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
      "array([[5],\n",
      "       [6]])>, <tf.Tensor: shape=(), dtype=float32, numpy=0.3>)]\n"
     ]
    }
   ],
   "source": [
    "x_train_uni = [[[1], [2]], [[3], [4]], [[5], [6]]]\n",
    "y_train_uni = [0.1, 0.2, 0.3]\n",
    "\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "print(train_univariate)\n",
    "print(list(train_univariate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))  \n",
    "# .from_tensor_slices : 첫 번째 차원을 따라 슬라이스 된다. \n",
    "# // 입력 텐서의 구조를 유지하고 각 텐서의 첫 번째 차원을 제거하고 \n",
    "# 이를 데이터 세트 차원으로 사용한다. \n",
    "# 쉽게 말하면 데이터 셋을 구성한다고 볼 수 있음\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    # dataset.map : 요소별 변환\n",
    "    # dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "    # dataset = dataset.map(lambda x: x*2)\n",
    "    # 출력값이 [2,4,6] 으로 변환\n",
    "    .batch(batch_size)  # .batch : 데이터 배치의 크기를 설정 \n",
    "    # .take() 해당 배치를 몇 번 불러올지 결정\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)  \n",
    "    # .prefetch : 연산에 필요한 data를 미리 가져오는 것, memory latency를 숨길 수 있다.\n",
    "    # cpu가 연산을 하는 동안 다음 연산에 필요한 데이터를 유추한다는 것\n",
    "    # 쉽게 말해서 빠른 연산을 진행 할 수 있도록 도와준다.\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(\n",
    "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1632722d940cb2b6b13e3b44c982a63c5a301e89d847959e11395d64211a8fb4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 ('tf114')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
