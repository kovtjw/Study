{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 구성요소\n",
    "torch: 텐서를 생성하는 라이브러리\n",
    "\n",
    "torch.autograd: 자동미분 기능을 제공하는 라이브러리\n",
    "\n",
    "torch.nn: 신경망을 생성하는 라이브러리\n",
    "\n",
    "torch.multiprocessing: 병럴처리 기능을 제공하는 라이브러리\n",
    "\n",
    "torch.utils: 데이터 조작 등 유틸리티 기능 제공\n",
    "\n",
    "torch.legacy(./nn/.optim): Torch로부터 포팅해온 코드\n",
    "\n",
    "torch.onnx: ONNX(Open Neural Network Exchange)\n",
    "\n",
    "서로 다른 프레임워크 간의 모델을 공유할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 \n",
    "- 넘파이의 ndarray와 유사\n",
    "- gpu를 사용한 연산 가속도 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu102'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7911, 0.8859],\n",
      "        [0.8132, 1.6774],\n",
      "        [0.8670, 0.9302],\n",
      "        [0.2295, 0.5214]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 5.9694e-39],\n",
      "        [1.7375e-04, 2.6447e+20]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4,2, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0000, 2.3000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3,2.3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= x.new_ones(2,4,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2067,  0.4243,  0.8509,  0.4112],\n",
       "        [ 0.0548,  0.1346, -1.0445, -1.7295]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2067,  0.4243,  0.8509,  0.4112],\n",
       "        [ 0.0548,  0.1346, -1.0445, -1.7295]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9256, 0.6837, 0.9846, 0.0570],\n",
      "        [0.9759, 0.3740, 0.5551, 0.5646]])\n",
      "tensor([[0.4368, 0.0567, 0.8209, 0.7956],\n",
      "        [0.4982, 0.9556, 0.1002, 0.4500]])\n",
      "tensor([[1.3624, 0.7404, 1.8054, 0.8526],\n",
      "        [1.4741, 1.3296, 0.6553, 1.0146]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,4)\n",
    "y = torch.rand(2,4)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3624, 0.7404, 1.8054, 0.8526],\n",
      "        [1.4741, 1.3296, 0.6553, 1.0146]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3624, 0.7404, 1.8054, 0.8526],\n",
      "        [1.4741, 1.3296, 0.6553, 1.0146]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(2,4)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9256, 0.6837, 0.9846, 0.0570],\n",
      "        [0.9759, 0.3740, 0.5551, 0.5646]])\n",
      "tensor([[0.4368, 0.0567, 0.8209, 0.7956],\n",
      "        [0.4982, 0.9556, 0.1002, 0.4500]])\n",
      "tensor([[1.3624, 0.7404, 1.8054, 0.8526],\n",
      "        [1.4741, 1.3296, 0.6553, 1.0146]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3,],\n",
    "                  [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(x - y)\n",
    "print(torch.sub(x,y))\n",
    "print(x.sub(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2., 12.],\n",
      "        [30., 56.]])\n",
      "tensor([[ 2., 12.],\n",
      "        [30., 56.]])\n",
      "tensor([[ 2., 12.],\n",
      "        [30., 56.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3,],\n",
    "                  [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(x * y)\n",
    "print(torch.mul(x,y))\n",
    "print(x.mul(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.7500],\n",
      "        [0.8333, 0.8750]])\n",
      "tensor([[0.5000, 0.7500],\n",
      "        [0.8333, 0.8750]])\n",
      "tensor([[0.5000, 0.7500],\n",
      "        [0.8333, 0.8750]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3,],\n",
    "                  [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(x / y)\n",
    "print(torch.div(x,y))\n",
    "print(x.div(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20., 28.],\n",
      "        [52., 76.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3,],\n",
    "                  [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(torch.mm(x,y)) # 행렬 곱\n",
    "print(torch.sub(x,y))\n",
    "print(x.sub(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 3.],\n",
      "        [5., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0917,  0.1028, -0.7288, -1.4977,  0.1590],\n",
      "        [ 0.2283, -0.8846, -1.3181, -0.1121,  1.4985],\n",
      "        [-0.2001,  1.3655,  1.6349,  0.6166, -0.2644],\n",
      "        [ 0.8133,  0.3713, -0.3327,  1.5859, -0.5421]])\n",
      "tensor([-1.0917,  0.1028, -0.7288, -1.4977,  0.1590,  0.2283, -0.8846, -1.3181,\n",
      "        -0.1121,  1.4985, -0.2001,  1.3655,  1.6349,  0.6166, -0.2644,  0.8133,\n",
      "         0.3713, -0.3327,  1.5859, -0.5421])\n",
      "tensor([[-1.0917,  0.1028, -0.7288, -1.4977],\n",
      "        [ 0.1590,  0.2283, -0.8846, -1.3181],\n",
      "        [-0.1121,  1.4985, -0.2001,  1.3655],\n",
      "        [ 1.6349,  0.6166, -0.2644,  0.8133],\n",
      "        [ 0.3713, -0.3327,  1.5859, -0.5421]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,5)\n",
    "y = x.view(20)\n",
    "z = x.view(5,-1)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3771])\n",
      "-0.37710681557655334\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0731])\n",
      "-1.0730844736099243\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7661, 0.6702, 0.8275],\n",
      "         [0.3743, 0.1274, 0.3112],\n",
      "         [0.4816, 0.9637, 0.7661]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(1,3,3)\n",
    "print(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7661, 0.6702, 0.8275],\n",
      "        [0.3743, 0.1274, 0.3112],\n",
      "        [0.4816, 0.9637, 0.7661]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.squeeze()  # 즙을 짜다 >> 차원을 축소해준다.  ([1, 3, 3]) > ([3, 3])\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2854, 0.6024, 0.0052],\n",
      "         [0.8548, 0.4825, 0.2788],\n",
      "         [0.8705, 0.4596, 0.9567]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1,3,3)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2854, 0.6024, 0.0052],\n",
      "          [0.8548, 0.4825, 0.2788],\n",
      "          [0.8705, 0.4596, 0.9567]]]])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.unsqueeze(dim=0)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "print(torch.stack([x,y,z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,b, tensor([[[-0.8485, -0.6198, -1.0138],\n",
      "         [ 0.6524,  1.9700, -0.5484],\n",
      "         [-0.6696, -0.8726, -0.4605]]]) tensor([[[-1.7770, -0.5420, -1.1710],\n",
      "         [-0.6981, -0.0857,  0.7953],\n",
      "         [-0.0607,  0.9694, -0.4955]]])\n",
      "c tensor([[[-0.8485, -0.6198, -1.0138],\n",
      "         [ 0.6524,  1.9700, -0.5484],\n",
      "         [-0.6696, -0.8726, -0.4605]],\n",
      "\n",
      "        [[-1.7770, -0.5420, -1.1710],\n",
      "         [-0.6981, -0.0857,  0.7953],\n",
      "         [-0.0607,  0.9694, -0.4955]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,3)\n",
    "b = torch.randn(1,3,3)\n",
    "print('a,b,',a,b)\n",
    "c = torch.cat((a,b), dim=0)\n",
    "print('c',c)\n",
    "print(c.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8597, 0.1403, 0.5543, 0.6685, 0.1058, 0.1982],\n",
      "        [0.1710, 0.0826, 0.1305, 0.8761, 0.0841, 0.8190],\n",
      "        [0.7191, 0.3510, 0.7268, 0.3222, 0.0488, 0.3424]])\n",
      "tensor([[0.8597, 0.1403],\n",
      "        [0.1710, 0.0826],\n",
      "        [0.7191, 0.3510]])\n",
      "tensor([[0.5543, 0.6685],\n",
      "        [0.1305, 0.8761],\n",
      "        [0.7268, 0.3222]])\n",
      "tensor([[0.1058, 0.1982],\n",
      "        [0.0841, 0.8190],\n",
      "        [0.0488, 0.3424]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "t1,t2,t3 = torch.chunk(tensor,3,dim=1)\n",
    "print(tensor)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6333, 0.4820, 0.7776, 0.1099, 0.4928, 0.5476],\n",
      "        [0.1215, 0.1559, 0.0390, 0.2725, 0.0619, 0.3278],\n",
      "        [0.7219, 0.0395, 0.2690, 0.9045, 0.4667, 0.8252]])\n",
      "tensor([[0.6333, 0.4820, 0.7776],\n",
      "        [0.1215, 0.1559, 0.0390],\n",
      "        [0.7219, 0.0395, 0.2690]])\n",
      "tensor([[0.1099, 0.4928, 0.5476],\n",
      "        [0.2725, 0.0619, 0.3278],\n",
      "        [0.9045, 0.4667, 0.8252]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "t1,t2 = torch.split(tensor, 3, dim=1)\n",
    "print(tensor)\n",
    "print(t1)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(7)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b=a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0839])\n",
      "1.0838581323623657\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'is_availabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1596/1412313701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_availabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'is_availabel'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_availabel() else 'cpu')\n",
    "\n",
    "y = torch.ones_like(x, device=device)\n",
    "x = x.to(device)\n",
    "z = x+y\n",
    "print(device)\n",
    "print(z)\n",
    "print(z)\n",
    "print(z.to('cpu', torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002353F7F35B0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[72., 72., 72.],\n",
      "        [72., 72., 72.],\n",
      "        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*2\n",
    "out =z.mean()\n",
    "print(z, out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[ 0.2805,  1.0556,  1.6407],\n",
      "        [-8.2536,  1.4984,  9.8198],\n",
      "        [ 0.3998,  1.1398,  0.4759]], requires_grad=True)\n",
      "<SumBackward0 object at 0x000002353DB04400>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad_(True))\n",
    "\n",
    "b= (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6667, 2.6667, 2.6667],\n",
      "        [2.6667, 2.6667, 2.6667],\n",
      "        [2.6667, 2.6667, 2.6667]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[512., 512., 512.],\n",
      "        [512., 512., 512.],\n",
      "        [512., 512., 512.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.randn(3,requires_grad=True)\n",
    "\n",
    "y = x*2 \n",
    "while y.data.norm()<1000:\n",
    "    y = y*2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Mismatch in shape: grad_output[0] has a shape of torch.Size([3]) and output[0] has a shape of torch.Size([3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14924/3171016541.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 raise RuntimeError(\"Mismatch in shape: grad_output[\"\n\u001b[0m\u001b[0;32m     35\u001b[0m                                    \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"] has a shape of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                                    \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" and output[\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Mismatch in shape: grad_output[0] has a shape of torch.Size([3]) and output[0] has a shape of torch.Size([3, 3])."
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1,1.0,0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_np = torch.tensor(data)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-math.pi,math.pi,2000)\n",
    "y = np.sin(x)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4747391994754476,\n",
       " 2.3228543966741215,\n",
       " 0.8735080167962913,\n",
       " -0.3816618835367902)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "a,b,c,d,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 28840.110654316057\n",
      "199 28840.110654316057\n",
      "299 28840.110654316057\n",
      "399 28840.110654316057\n",
      "499 28840.110654316057\n",
      "599 28840.110654316057\n",
      "699 28840.110654316057\n",
      "799 28840.110654316057\n",
      "899 28840.110654316057\n",
      "999 28840.110654316057\n",
      "1099 28840.110654316057\n",
      "1199 28840.110654316057\n",
      "1299 28840.110654316057\n",
      "1399 28840.110654316057\n",
      "1499 28840.110654316057\n",
      "1599 28840.110654316057\n",
      "1699 28840.110654316057\n",
      "1799 28840.110654316057\n",
      "1899 28840.110654316057\n",
      "1999 28840.110654316057\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = a+b*x+c*x**2+d*x**3\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 ==99:\n",
    "        print(t,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_y_pred = 2.0 * (y_pred-y)\n",
    "grad_a = grad_y_pred.sum()\n",
    "grad_b = (grad_y_pred*x).sum()\n",
    "grad_c = (grad_y_pred*x**2).sum()\n",
    "grad_d = (grad_y_pred*x**3).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: y = -0.48434664808857536+2.32605567497736+0.8115552334520321 x^2+-0.33726574825178723dx^3\n"
     ]
    }
   ],
   "source": [
    "a-=learning_rate*grad_a\n",
    "b-=learning_rate*grad_b\n",
    "c-=learning_rate*grad_c\n",
    "d-=learning_rate*grad_d\n",
    "\n",
    "print(f'Result: y = {a}+{b}+{c} x^2+{d}dx^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio # 설치필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "import boto3 # 설치 필요\n",
    "from botocore import UNSIGNED\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAMPLE_DIR = \"_sample_data\"\n",
    "SAMPLE_WAV_PATH = os.path.join(_SAMPLE_DIR, '00001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0194e-38, 1.0469e-38, 1.0010e-38, 8.9081e-39],\n",
       "        [8.9082e-39, 5.9694e-39, 8.9082e-39, 1.0194e-38],\n",
       "        [9.1837e-39, 4.6837e-39, 9.9184e-39, 9.0000e-39],\n",
       "        [1.0561e-38, 1.0653e-38, 4.1327e-39, 8.9082e-39],\n",
       "        [9.8265e-39, 9.4592e-39, 1.0561e-38, 1.0653e-38]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3256, 0.0289, 0.4751, 0.7824, 0.0095, 0.6371],\n",
       "        [0.0025, 0.4662, 0.6322, 0.6490, 0.5185, 0.5793],\n",
       "        [0.6582, 0.4892, 0.4871, 0.9939, 0.1942, 0.0390],\n",
       "        [0.6780, 0.9328, 0.0574, 0.3729, 0.9678, 0.5275],\n",
       "        [0.3979, 0.9313, 0.5950, 0.6595, 0.3276, 0.7717]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13,  4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [13,4]\n",
    "r = np.array([4,56,7])\n",
    "torch.tensor(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 56,  7], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3838, 0.7203],\n",
       "        [1.6343, 0.6227]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4816, 0.3266],\n",
       "        [1.2257, 0.7006]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4816, 0.3266],\n",
       "        [1.2257, 0.7006]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)  # 변수 대체하기 위해 '_' 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4816, 0.3266],\n",
      "        [1.2257, 0.7006]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2450, 0.6765])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5942, 0.2136, 0.0646, 0.5913, 0.4445, 0.8263, 0.9547, 0.6631],\n",
      "        [0.7495, 0.3924, 0.4028, 0.2224, 0.5161, 0.1789, 0.5077, 0.3394],\n",
      "        [0.9407, 0.6543, 0.6558, 0.7594, 0.4599, 0.8545, 0.6242, 0.7989],\n",
      "        [0.3419, 0.0320, 0.9349, 0.5169, 0.8084, 0.1131, 0.8281, 0.6109],\n",
      "        [0.6232, 0.7817, 0.7463, 0.0111, 0.5582, 0.8447, 0.7059, 0.2552],\n",
      "        [0.5122, 0.0646, 0.1878, 0.2591, 0.7385, 0.1080, 0.5525, 0.0473],\n",
      "        [0.7840, 0.2525, 0.2003, 0.9739, 0.0839, 0.0023, 0.3729, 0.5253],\n",
      "        [0.1289, 0.8903, 0.1695, 0.8753, 0.3719, 0.5376, 0.5112, 0.8858]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(8,8)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5942, 0.2136, 0.0646, 0.5913, 0.4445, 0.8263, 0.9547, 0.6631, 0.7495,\n",
       "        0.3924, 0.4028, 0.2224, 0.5161, 0.1789, 0.5077, 0.3394, 0.9407, 0.6543,\n",
       "        0.6558, 0.7594, 0.4599, 0.8545, 0.6242, 0.7989, 0.3419, 0.0320, 0.9349,\n",
       "        0.5169, 0.8084, 0.1131, 0.8281, 0.6109, 0.6232, 0.7817, 0.7463, 0.0111,\n",
       "        0.5582, 0.8447, 0.7059, 0.2552, 0.5122, 0.0646, 0.1878, 0.2591, 0.7385,\n",
       "        0.1080, 0.5525, 0.0473, 0.7840, 0.2525, 0.2003, 0.9739, 0.0839, 0.0023,\n",
       "        0.3729, 0.5253, 0.1289, 0.8903, 0.1695, 0.8753, 0.3719, 0.5376, 0.5112,\n",
       "        0.8858])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5942, 0.2136, 0.0646, 0.5913, 0.4445, 0.8263, 0.9547, 0.6631, 0.7495,\n",
       "         0.3924, 0.4028, 0.2224, 0.5161, 0.1789, 0.5077, 0.3394],\n",
       "        [0.9407, 0.6543, 0.6558, 0.7594, 0.4599, 0.8545, 0.6242, 0.7989, 0.3419,\n",
       "         0.0320, 0.9349, 0.5169, 0.8084, 0.1131, 0.8281, 0.6109],\n",
       "        [0.6232, 0.7817, 0.7463, 0.0111, 0.5582, 0.8447, 0.7059, 0.2552, 0.5122,\n",
       "         0.0646, 0.1878, 0.2591, 0.7385, 0.1080, 0.5525, 0.0473],\n",
       "        [0.7840, 0.2525, 0.2003, 0.9739, 0.0839, 0.0023, 0.3729, 0.5253, 0.1289,\n",
       "         0.8903, 0.1695, 0.8753, 0.3719, 0.5376, 0.5112, 0.8858]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(4,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5942],\n",
       "         [0.2136],\n",
       "         [0.0646],\n",
       "         [0.5913],\n",
       "         [0.4445],\n",
       "         [0.8263],\n",
       "         [0.9547],\n",
       "         [0.6631],\n",
       "         [0.7495],\n",
       "         [0.3924],\n",
       "         [0.4028],\n",
       "         [0.2224],\n",
       "         [0.5161],\n",
       "         [0.1789],\n",
       "         [0.5077],\n",
       "         [0.3394]],\n",
       "\n",
       "        [[0.9407],\n",
       "         [0.6543],\n",
       "         [0.6558],\n",
       "         [0.7594],\n",
       "         [0.4599],\n",
       "         [0.8545],\n",
       "         [0.6242],\n",
       "         [0.7989],\n",
       "         [0.3419],\n",
       "         [0.0320],\n",
       "         [0.9349],\n",
       "         [0.5169],\n",
       "         [0.8084],\n",
       "         [0.1131],\n",
       "         [0.8281],\n",
       "         [0.6109]],\n",
       "\n",
       "        [[0.6232],\n",
       "         [0.7817],\n",
       "         [0.7463],\n",
       "         [0.0111],\n",
       "         [0.5582],\n",
       "         [0.8447],\n",
       "         [0.7059],\n",
       "         [0.2552],\n",
       "         [0.5122],\n",
       "         [0.0646],\n",
       "         [0.1878],\n",
       "         [0.2591],\n",
       "         [0.7385],\n",
       "         [0.1080],\n",
       "         [0.5525],\n",
       "         [0.0473]],\n",
       "\n",
       "        [[0.7840],\n",
       "         [0.2525],\n",
       "         [0.2003],\n",
       "         [0.9739],\n",
       "         [0.0839],\n",
       "         [0.0023],\n",
       "         [0.3729],\n",
       "         [0.5253],\n",
       "         [0.1289],\n",
       "         [0.8903],\n",
       "         [0.1695],\n",
       "         [0.8753],\n",
       "         [0.3719],\n",
       "         [0.5376],\n",
       "         [0.5112],\n",
       "         [0.8858]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5941649 , 0.21362704, 0.06459856, 0.5913336 , 0.4444502 ,\n",
       "        0.82634014, 0.9547417 , 0.66312593],\n",
       "       [0.74945873, 0.39237255, 0.40280795, 0.22237623, 0.5160693 ,\n",
       "        0.17890614, 0.5076993 , 0.339446  ],\n",
       "       [0.94070905, 0.65428376, 0.6557749 , 0.7593991 , 0.45986205,\n",
       "        0.85453683, 0.6241721 , 0.79886794],\n",
       "       [0.34189236, 0.03197491, 0.9348733 , 0.516884  , 0.80841357,\n",
       "        0.11307174, 0.82812035, 0.6108662 ],\n",
       "       [0.6232348 , 0.7817314 , 0.74625707, 0.01111048, 0.5582403 ,\n",
       "        0.84466684, 0.70593697, 0.25522238],\n",
       "       [0.5121692 , 0.06458092, 0.18780792, 0.2591375 , 0.7384654 ,\n",
       "        0.10797185, 0.55252594, 0.04732877],\n",
       "       [0.78401184, 0.2525339 , 0.20027876, 0.9738588 , 0.08385247,\n",
       "        0.00227743, 0.37286824, 0.5253397 ],\n",
       "       [0.12888992, 0.890258  , 0.16950339, 0.8753067 , 0.37186372,\n",
       "        0.5376426 , 0.51121086, 0.88579243]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= x.numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2,2,requires_grad=True)   # requires_grad=True 연산을 추적해준다??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = 2*y**2\n",
    "res = z.mean()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [00:48, 3520336.56it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transf =tr.Compose([tr.Resize(8),tr.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download=True, transform=transf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([3, 8, 8]) pytorch에서는 채널 수가 맨 앞에 위치한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 8, 8])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([50, 3, 8, 8]) \n",
    "배치  채널 이미지 사이즈(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes cifar-10-batches-py. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6700/1974224763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtransf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     ):\n\u001b[1;32m--> 310\u001b[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[0;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m    145\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[1;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             )\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf\"Supported extensions are: {', '.join(extensions)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Found no valid file for the classes cifar-10-batches-py. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "transf = tr.Compose([tr.Resize(16),tr.ToTensor()])\n",
    "trainset = torchvision.datasets.ImageFolder(root = './data',transform=transf)\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=False, num_workers=2)\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 32, 32, 3) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images =np.random.randint(256,size=(20,32,32,3))\n",
    "train_labels = np.random.randint(2,size = (20,1))\n",
    "\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.x_data = self.x_data.permute(0,3,1,2)  ###이미지 개수, 채널 수, 이미지 너비, 높이\n",
    "        self.y_data = torch.LongTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorData(train_images, train_labels)\n",
    "train_loader = DataLoader(train_data, batch_size = 10, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class TensorData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform\n",
    "        self.len = len(y_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
